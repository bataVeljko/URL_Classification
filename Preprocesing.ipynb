{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import re\n",
    "import ipaddress as ip\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_delims = [\":\", \"/\", \"?\", \"#\", \"[\", \"]\", \"@\"]\n",
    "sub_delims = [\"!\", \"$\", \"&\", \"'\", \"(\", \")\", \"*\", \"+\", \",\", \";\", \"=\"]\n",
    "reserved_characters = gen_delims + sub_delims\n",
    "unreserved_characters = [\"-\", \".\", \"_\", \"~\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_class(x):\n",
    "    return 1 if x == 'good' else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_known_tlds():\n",
    "    with open('known_tlds.txt', 'r') as file:\n",
    "        tlds = file.read().split('\\n')\n",
    "        tlds = [tld.lower() for tld in tlds]\n",
    "        return tlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'aarp',\n",
       " 'abarth',\n",
       " 'abb',\n",
       " 'abbott',\n",
       " 'abbvie',\n",
       " 'abc',\n",
       " 'able',\n",
       " 'abogado',\n",
       " 'abudhabi',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'accenture',\n",
       " 'accountant',\n",
       " 'accountants',\n",
       " 'aco',\n",
       " 'actor',\n",
       " 'ad',\n",
       " 'adac',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'ae',\n",
       " 'aeg',\n",
       " 'aero',\n",
       " 'aetna',\n",
       " 'af',\n",
       " 'afamilycompany',\n",
       " 'afl',\n",
       " 'africa',\n",
       " 'ag',\n",
       " 'agakhan',\n",
       " 'agency',\n",
       " 'ai',\n",
       " 'aig',\n",
       " 'airbus',\n",
       " 'airforce',\n",
       " 'airtel',\n",
       " 'akdn',\n",
       " 'al',\n",
       " 'alfaromeo',\n",
       " 'alibaba',\n",
       " 'alipay',\n",
       " 'allfinanz',\n",
       " 'allstate',\n",
       " 'ally',\n",
       " 'alsace',\n",
       " 'alstom',\n",
       " 'am',\n",
       " 'amazon',\n",
       " 'americanexpress',\n",
       " 'americanfamily',\n",
       " 'amex',\n",
       " 'amfam',\n",
       " 'amica',\n",
       " 'amsterdam',\n",
       " 'analytics',\n",
       " 'android',\n",
       " 'anquan',\n",
       " 'anz',\n",
       " 'ao',\n",
       " 'aol',\n",
       " 'apartments',\n",
       " 'app',\n",
       " 'apple',\n",
       " 'aq',\n",
       " 'aquarelle',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'aramco',\n",
       " 'archi',\n",
       " 'army',\n",
       " 'arpa',\n",
       " 'art',\n",
       " 'arte',\n",
       " 'as',\n",
       " 'asda',\n",
       " 'asia',\n",
       " 'associates',\n",
       " 'at',\n",
       " 'athleta',\n",
       " 'attorney',\n",
       " 'au',\n",
       " 'auction',\n",
       " 'audi',\n",
       " 'audible',\n",
       " 'audio',\n",
       " 'auspost',\n",
       " 'author',\n",
       " 'auto',\n",
       " 'autos',\n",
       " 'avianca',\n",
       " 'aw',\n",
       " 'aws',\n",
       " 'ax',\n",
       " 'axa',\n",
       " 'az',\n",
       " 'azure',\n",
       " 'ba',\n",
       " 'baby',\n",
       " 'baidu',\n",
       " 'banamex',\n",
       " 'bananarepublic',\n",
       " 'band',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barcelona',\n",
       " 'barclaycard',\n",
       " 'barclays',\n",
       " 'barefoot',\n",
       " 'bargains',\n",
       " 'baseball',\n",
       " 'basketball',\n",
       " 'bauhaus',\n",
       " 'bayern',\n",
       " 'bb',\n",
       " 'bbc',\n",
       " 'bbt',\n",
       " 'bbva',\n",
       " 'bcg',\n",
       " 'bcn',\n",
       " 'bd',\n",
       " 'be',\n",
       " 'beats',\n",
       " 'beauty',\n",
       " 'beer',\n",
       " 'bentley',\n",
       " 'berlin',\n",
       " 'best',\n",
       " 'bestbuy',\n",
       " 'bet',\n",
       " 'bf',\n",
       " 'bg',\n",
       " 'bh',\n",
       " 'bharti',\n",
       " 'bi',\n",
       " 'bible',\n",
       " 'bid',\n",
       " 'bike',\n",
       " 'bing',\n",
       " 'bingo',\n",
       " 'bio',\n",
       " 'biz',\n",
       " 'bj',\n",
       " 'black',\n",
       " 'blackfriday',\n",
       " 'blockbuster',\n",
       " 'blog',\n",
       " 'bloomberg',\n",
       " 'blue',\n",
       " 'bm',\n",
       " 'bms',\n",
       " 'bmw',\n",
       " 'bn',\n",
       " 'bnpparibas',\n",
       " 'bo',\n",
       " 'boats',\n",
       " 'boehringer',\n",
       " 'bofa',\n",
       " 'bom',\n",
       " 'bond',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booking',\n",
       " 'bosch',\n",
       " 'bostik',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'boutique',\n",
       " 'box',\n",
       " 'br',\n",
       " 'bradesco',\n",
       " 'bridgestone',\n",
       " 'broadway',\n",
       " 'broker',\n",
       " 'brother',\n",
       " 'brussels',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'budapest',\n",
       " 'bugatti',\n",
       " 'build',\n",
       " 'builders',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'bv',\n",
       " 'bw',\n",
       " 'by',\n",
       " 'bz',\n",
       " 'bzh',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cafe',\n",
       " 'cal',\n",
       " 'call',\n",
       " 'calvinklein',\n",
       " 'cam',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'cancerresearch',\n",
       " 'canon',\n",
       " 'capetown',\n",
       " 'capital',\n",
       " 'capitalone',\n",
       " 'car',\n",
       " 'caravan',\n",
       " 'cards',\n",
       " 'care',\n",
       " 'career',\n",
       " 'careers',\n",
       " 'cars',\n",
       " 'casa',\n",
       " 'case',\n",
       " 'caseih',\n",
       " 'cash',\n",
       " 'casino',\n",
       " 'cat',\n",
       " 'catering',\n",
       " 'catholic',\n",
       " 'cba',\n",
       " 'cbn',\n",
       " 'cbre',\n",
       " 'cbs',\n",
       " 'cc',\n",
       " 'cd',\n",
       " 'ceb',\n",
       " 'center',\n",
       " 'ceo',\n",
       " 'cern',\n",
       " 'cf',\n",
       " 'cfa',\n",
       " 'cfd',\n",
       " 'cg',\n",
       " 'ch',\n",
       " 'chanel',\n",
       " 'channel',\n",
       " 'charity',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'chintai',\n",
       " 'christmas',\n",
       " 'chrome',\n",
       " 'church',\n",
       " 'ci',\n",
       " 'cipriani',\n",
       " 'circle',\n",
       " 'cisco',\n",
       " 'citadel',\n",
       " 'citi',\n",
       " 'citic',\n",
       " 'city',\n",
       " 'cityeats',\n",
       " 'ck',\n",
       " 'cl',\n",
       " 'claims',\n",
       " 'cleaning',\n",
       " 'click',\n",
       " 'clinic',\n",
       " 'clinique',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'club',\n",
       " 'clubmed',\n",
       " 'cm',\n",
       " 'cn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'codes',\n",
       " 'coffee',\n",
       " 'college',\n",
       " 'cologne',\n",
       " 'com',\n",
       " 'comcast',\n",
       " 'commbank',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'computer',\n",
       " 'comsec',\n",
       " 'condos',\n",
       " 'construction',\n",
       " 'consulting',\n",
       " 'contact',\n",
       " 'contractors',\n",
       " 'cooking',\n",
       " 'cookingchannel',\n",
       " 'cool',\n",
       " 'coop',\n",
       " 'corsica',\n",
       " 'country',\n",
       " 'coupon',\n",
       " 'coupons',\n",
       " 'courses',\n",
       " 'cpa',\n",
       " 'cr',\n",
       " 'credit',\n",
       " 'creditcard',\n",
       " 'creditunion',\n",
       " 'cricket',\n",
       " 'crown',\n",
       " 'crs',\n",
       " 'cruise',\n",
       " 'cruises',\n",
       " 'csc',\n",
       " 'cu',\n",
       " 'cuisinella',\n",
       " 'cv',\n",
       " 'cw',\n",
       " 'cx',\n",
       " 'cy',\n",
       " 'cymru',\n",
       " 'cyou',\n",
       " 'cz',\n",
       " 'dabur',\n",
       " 'dad',\n",
       " 'dance',\n",
       " 'data',\n",
       " 'date',\n",
       " 'dating',\n",
       " 'datsun',\n",
       " 'day',\n",
       " 'dclk',\n",
       " 'dds',\n",
       " 'de',\n",
       " 'deal',\n",
       " 'dealer',\n",
       " 'deals',\n",
       " 'degree',\n",
       " 'delivery',\n",
       " 'dell',\n",
       " 'deloitte',\n",
       " 'delta',\n",
       " 'democrat',\n",
       " 'dental',\n",
       " 'dentist',\n",
       " 'desi',\n",
       " 'design',\n",
       " 'dev',\n",
       " 'dhl',\n",
       " 'diamonds',\n",
       " 'diet',\n",
       " 'digital',\n",
       " 'direct',\n",
       " 'directory',\n",
       " 'discount',\n",
       " 'discover',\n",
       " 'dish',\n",
       " 'diy',\n",
       " 'dj',\n",
       " 'dk',\n",
       " 'dm',\n",
       " 'dnp',\n",
       " 'do',\n",
       " 'docs',\n",
       " 'doctor',\n",
       " 'dog',\n",
       " 'domains',\n",
       " 'dot',\n",
       " 'download',\n",
       " 'drive',\n",
       " 'dtv',\n",
       " 'dubai',\n",
       " 'duck',\n",
       " 'dunlop',\n",
       " 'dupont',\n",
       " 'durban',\n",
       " 'dvag',\n",
       " 'dvr',\n",
       " 'dz',\n",
       " 'earth',\n",
       " 'eat',\n",
       " 'ec',\n",
       " 'eco',\n",
       " 'edeka',\n",
       " 'edu',\n",
       " 'education',\n",
       " 'ee',\n",
       " 'eg',\n",
       " 'email',\n",
       " 'emerck',\n",
       " 'energy',\n",
       " 'engineer',\n",
       " 'engineering',\n",
       " 'enterprises',\n",
       " 'epson',\n",
       " 'equipment',\n",
       " 'er',\n",
       " 'ericsson',\n",
       " 'erni',\n",
       " 'es',\n",
       " 'esq',\n",
       " 'estate',\n",
       " 'et',\n",
       " 'etisalat',\n",
       " 'eu',\n",
       " 'eurovision',\n",
       " 'eus',\n",
       " 'events',\n",
       " 'exchange',\n",
       " 'expert',\n",
       " 'exposed',\n",
       " 'express',\n",
       " 'extraspace',\n",
       " 'fage',\n",
       " 'fail',\n",
       " 'fairwinds',\n",
       " 'faith',\n",
       " 'family',\n",
       " 'fan',\n",
       " 'fans',\n",
       " 'farm',\n",
       " 'farmers',\n",
       " 'fashion',\n",
       " 'fast',\n",
       " 'fedex',\n",
       " 'feedback',\n",
       " 'ferrari',\n",
       " 'ferrero',\n",
       " 'fi',\n",
       " 'fiat',\n",
       " 'fidelity',\n",
       " 'fido',\n",
       " 'film',\n",
       " 'final',\n",
       " 'finance',\n",
       " 'financial',\n",
       " 'fire',\n",
       " 'firestone',\n",
       " 'firmdale',\n",
       " 'fish',\n",
       " 'fishing',\n",
       " 'fit',\n",
       " 'fitness',\n",
       " 'fj',\n",
       " 'fk',\n",
       " 'flickr',\n",
       " 'flights',\n",
       " 'flir',\n",
       " 'florist',\n",
       " 'flowers',\n",
       " 'fly',\n",
       " 'fm',\n",
       " 'fo',\n",
       " 'foo',\n",
       " 'food',\n",
       " 'foodnetwork',\n",
       " 'football',\n",
       " 'ford',\n",
       " 'forex',\n",
       " 'forsale',\n",
       " 'forum',\n",
       " 'foundation',\n",
       " 'fox',\n",
       " 'fr',\n",
       " 'free',\n",
       " 'fresenius',\n",
       " 'frl',\n",
       " 'frogans',\n",
       " 'frontdoor',\n",
       " 'frontier',\n",
       " 'ftr',\n",
       " 'fujitsu',\n",
       " 'fujixerox',\n",
       " 'fun',\n",
       " 'fund',\n",
       " 'furniture',\n",
       " 'futbol',\n",
       " 'fyi',\n",
       " 'ga',\n",
       " 'gal',\n",
       " 'gallery',\n",
       " 'gallo',\n",
       " 'gallup',\n",
       " 'game',\n",
       " 'games',\n",
       " 'gap',\n",
       " 'garden',\n",
       " 'gay',\n",
       " 'gb',\n",
       " 'gbiz',\n",
       " 'gd',\n",
       " 'gdn',\n",
       " 'ge',\n",
       " 'gea',\n",
       " 'gent',\n",
       " 'genting',\n",
       " 'george',\n",
       " 'gf',\n",
       " 'gg',\n",
       " 'ggee',\n",
       " 'gh',\n",
       " 'gi',\n",
       " 'gift',\n",
       " 'gifts',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'gl',\n",
       " 'glade',\n",
       " 'glass',\n",
       " 'gle',\n",
       " 'global',\n",
       " 'globo',\n",
       " 'gm',\n",
       " 'gmail',\n",
       " 'gmbh',\n",
       " 'gmo',\n",
       " 'gmx',\n",
       " 'gn',\n",
       " 'godaddy',\n",
       " 'gold',\n",
       " 'goldpoint',\n",
       " 'golf',\n",
       " 'goo',\n",
       " 'goodyear',\n",
       " 'goog',\n",
       " 'google',\n",
       " 'gop',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'gp',\n",
       " 'gq',\n",
       " 'gr',\n",
       " 'grainger',\n",
       " 'graphics',\n",
       " 'gratis',\n",
       " 'green',\n",
       " 'gripe',\n",
       " 'grocery',\n",
       " 'group',\n",
       " 'gs',\n",
       " 'gt',\n",
       " 'gu',\n",
       " 'guardian',\n",
       " 'gucci',\n",
       " 'guge',\n",
       " 'guide',\n",
       " 'guitars',\n",
       " 'guru',\n",
       " 'gw',\n",
       " 'gy',\n",
       " 'hair',\n",
       " 'hamburg',\n",
       " 'hangout',\n",
       " 'haus',\n",
       " 'hbo',\n",
       " 'hdfc',\n",
       " 'hdfcbank',\n",
       " 'health',\n",
       " 'healthcare',\n",
       " 'help',\n",
       " 'helsinki',\n",
       " 'here',\n",
       " 'hermes',\n",
       " 'hgtv',\n",
       " 'hiphop',\n",
       " 'hisamitsu',\n",
       " 'hitachi',\n",
       " 'hiv',\n",
       " 'hk',\n",
       " 'hkt',\n",
       " 'hm',\n",
       " 'hn',\n",
       " 'hockey',\n",
       " 'holdings',\n",
       " 'holiday',\n",
       " 'homedepot',\n",
       " 'homegoods',\n",
       " 'homes',\n",
       " 'homesense',\n",
       " 'honda',\n",
       " 'horse',\n",
       " 'hospital',\n",
       " 'host',\n",
       " 'hosting',\n",
       " 'hot',\n",
       " 'hoteles',\n",
       " 'hotels',\n",
       " 'hotmail',\n",
       " 'house',\n",
       " 'how',\n",
       " 'hr',\n",
       " 'hsbc',\n",
       " 'ht',\n",
       " 'hu',\n",
       " 'hughes',\n",
       " 'hyatt',\n",
       " 'hyundai',\n",
       " 'ibm',\n",
       " 'icbc',\n",
       " 'ice',\n",
       " 'icu',\n",
       " 'id',\n",
       " 'ie',\n",
       " 'ieee',\n",
       " 'ifm',\n",
       " 'ikano',\n",
       " 'il',\n",
       " 'im',\n",
       " 'imamat',\n",
       " 'imdb',\n",
       " 'immo',\n",
       " 'immobilien',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'industries',\n",
       " 'infiniti',\n",
       " 'info',\n",
       " 'ing',\n",
       " 'ink',\n",
       " 'institute',\n",
       " 'insurance',\n",
       " 'insure',\n",
       " 'int',\n",
       " 'intel',\n",
       " 'international',\n",
       " 'intuit',\n",
       " 'investments',\n",
       " 'io',\n",
       " 'ipiranga',\n",
       " 'iq',\n",
       " 'ir',\n",
       " 'irish',\n",
       " 'is',\n",
       " 'ismaili',\n",
       " 'ist',\n",
       " 'istanbul',\n",
       " 'it',\n",
       " 'itau',\n",
       " 'itv',\n",
       " 'iveco',\n",
       " 'jaguar',\n",
       " 'java',\n",
       " 'jcb',\n",
       " 'jcp',\n",
       " 'je',\n",
       " 'jeep',\n",
       " 'jetzt',\n",
       " 'jewelry',\n",
       " 'jio',\n",
       " 'jll',\n",
       " 'jm',\n",
       " 'jmp',\n",
       " 'jnj',\n",
       " 'jo',\n",
       " 'jobs',\n",
       " 'joburg',\n",
       " 'jot',\n",
       " 'joy',\n",
       " 'jp',\n",
       " 'jpmorgan',\n",
       " 'jprs',\n",
       " 'juegos',\n",
       " 'juniper',\n",
       " 'kaufen',\n",
       " 'kddi',\n",
       " 'ke',\n",
       " 'kerryhotels',\n",
       " 'kerrylogistics',\n",
       " 'kerryproperties',\n",
       " 'kfh',\n",
       " 'kg',\n",
       " 'kh',\n",
       " 'ki',\n",
       " 'kia',\n",
       " 'kim',\n",
       " 'kinder',\n",
       " 'kindle',\n",
       " 'kitchen',\n",
       " 'kiwi',\n",
       " 'km',\n",
       " 'kn',\n",
       " 'koeln',\n",
       " 'komatsu',\n",
       " 'kosher',\n",
       " 'kp',\n",
       " 'kpmg',\n",
       " 'kpn',\n",
       " 'kr',\n",
       " 'krd',\n",
       " 'kred',\n",
       " 'kuokgroup',\n",
       " 'kw',\n",
       " 'ky',\n",
       " 'kyoto',\n",
       " 'kz',\n",
       " 'la',\n",
       " 'lacaixa',\n",
       " 'lamborghini',\n",
       " 'lamer',\n",
       " 'lancaster',\n",
       " 'lancia',\n",
       " 'land',\n",
       " 'landrover',\n",
       " 'lanxess',\n",
       " 'lasalle',\n",
       " 'lat',\n",
       " 'latino',\n",
       " 'latrobe',\n",
       " 'law',\n",
       " 'lawyer',\n",
       " 'lb',\n",
       " 'lc',\n",
       " 'lds',\n",
       " 'lease',\n",
       " 'leclerc',\n",
       " 'lefrak',\n",
       " 'legal',\n",
       " 'lego',\n",
       " 'lexus',\n",
       " 'lgbt',\n",
       " 'li',\n",
       " 'lidl',\n",
       " 'life',\n",
       " 'lifeinsurance',\n",
       " 'lifestyle',\n",
       " 'lighting',\n",
       " 'like',\n",
       " 'lilly',\n",
       " 'limited',\n",
       " 'limo',\n",
       " 'lincoln',\n",
       " 'linde',\n",
       " 'link',\n",
       " 'lipsy',\n",
       " 'live',\n",
       " 'living',\n",
       " 'lixil',\n",
       " 'lk',\n",
       " 'llc',\n",
       " 'llp',\n",
       " 'loan',\n",
       " 'loans',\n",
       " 'locker',\n",
       " 'locus',\n",
       " 'loft',\n",
       " 'lol',\n",
       " 'london',\n",
       " 'lotte',\n",
       " 'lotto',\n",
       " 'love',\n",
       " 'lpl',\n",
       " 'lplfinancial',\n",
       " 'lr',\n",
       " 'ls',\n",
       " 'lt',\n",
       " 'ltd',\n",
       " 'ltda',\n",
       " 'lu',\n",
       " 'lundbeck',\n",
       " 'lupin',\n",
       " 'luxe',\n",
       " 'luxury',\n",
       " 'lv',\n",
       " 'ly',\n",
       " 'ma',\n",
       " 'macys',\n",
       " 'madrid',\n",
       " 'maif',\n",
       " 'maison',\n",
       " 'makeup',\n",
       " 'man',\n",
       " 'management',\n",
       " 'mango',\n",
       " 'map',\n",
       " 'market',\n",
       " 'marketing',\n",
       " 'markets',\n",
       " 'marriott',\n",
       " 'marshalls',\n",
       " 'maserati',\n",
       " 'mattel',\n",
       " 'mba',\n",
       " 'mc',\n",
       " 'mckinsey',\n",
       " 'md',\n",
       " 'me',\n",
       " 'med',\n",
       " 'media',\n",
       " 'meet',\n",
       " 'melbourne',\n",
       " 'meme',\n",
       " 'memorial',\n",
       " 'men',\n",
       " 'menu',\n",
       " 'merckmsd',\n",
       " 'metlife',\n",
       " 'mg',\n",
       " 'mh',\n",
       " 'miami',\n",
       " 'microsoft',\n",
       " 'mil',\n",
       " 'mini',\n",
       " 'mint',\n",
       " 'mit',\n",
       " 'mitsubishi',\n",
       " 'mk',\n",
       " 'ml',\n",
       " 'mlb',\n",
       " 'mls',\n",
       " 'mm',\n",
       " 'mma',\n",
       " 'mn',\n",
       " 'mo',\n",
       " 'mobi',\n",
       " 'mobile',\n",
       " 'moda',\n",
       " 'moe',\n",
       " 'moi',\n",
       " 'mom',\n",
       " 'monash',\n",
       " 'money',\n",
       " 'monster',\n",
       " 'mormon',\n",
       " 'mortgage',\n",
       " 'moscow',\n",
       " 'moto',\n",
       " 'motorcycles',\n",
       " 'mov',\n",
       " 'movie',\n",
       " 'mp',\n",
       " 'mq',\n",
       " 'mr',\n",
       " 'ms',\n",
       " 'msd',\n",
       " 'mt',\n",
       " 'mtn',\n",
       " 'mtr',\n",
       " 'mu',\n",
       " 'museum',\n",
       " 'mutual',\n",
       " 'mv',\n",
       " 'mw',\n",
       " 'mx',\n",
       " 'my',\n",
       " 'mz',\n",
       " 'na',\n",
       " 'nab',\n",
       " 'nagoya',\n",
       " 'name',\n",
       " 'nationwide',\n",
       " 'natura',\n",
       " 'navy',\n",
       " 'nba',\n",
       " 'nc',\n",
       " 'ne',\n",
       " 'nec',\n",
       " 'net',\n",
       " 'netbank',\n",
       " 'netflix',\n",
       " 'network',\n",
       " 'neustar',\n",
       " 'new',\n",
       " 'newholland',\n",
       " 'news',\n",
       " 'next',\n",
       " 'nextdirect',\n",
       " 'nexus',\n",
       " 'nf',\n",
       " 'nfl',\n",
       " 'ng',\n",
       " 'ngo',\n",
       " 'nhk',\n",
       " 'ni',\n",
       " 'nico',\n",
       " 'nike',\n",
       " 'nikon',\n",
       " 'ninja',\n",
       " 'nissan',\n",
       " 'nissay',\n",
       " 'nl',\n",
       " 'no',\n",
       " 'nokia',\n",
       " 'northwesternmutual',\n",
       " 'norton',\n",
       " 'now',\n",
       " 'nowruz',\n",
       " 'nowtv',\n",
       " 'np',\n",
       " 'nr',\n",
       " 'nra',\n",
       " 'nrw',\n",
       " 'ntt',\n",
       " 'nu',\n",
       " 'nyc',\n",
       " 'nz',\n",
       " 'obi',\n",
       " 'observer',\n",
       " 'off',\n",
       " 'office',\n",
       " 'okinawa',\n",
       " 'olayan',\n",
       " 'olayangroup',\n",
       " 'oldnavy',\n",
       " 'ollo',\n",
       " 'om',\n",
       " 'omega',\n",
       " 'one',\n",
       " 'ong',\n",
       " 'onl',\n",
       " 'online',\n",
       " 'onyourside',\n",
       " 'ooo',\n",
       " 'open',\n",
       " 'oracle',\n",
       " 'orange',\n",
       " 'org',\n",
       " 'organic',\n",
       " 'origins',\n",
       " 'osaka',\n",
       " 'otsuka',\n",
       " 'ott',\n",
       " 'ovh',\n",
       " 'pa',\n",
       " 'page',\n",
       " 'panasonic',\n",
       " 'paris',\n",
       " 'pars',\n",
       " 'partners',\n",
       " 'parts',\n",
       " 'party',\n",
       " 'passagens',\n",
       " 'pay',\n",
       " 'pccw',\n",
       " 'pe',\n",
       " 'pet',\n",
       " 'pf',\n",
       " 'pfizer',\n",
       " 'pg',\n",
       " 'ph',\n",
       " 'pharmacy',\n",
       " 'phd',\n",
       " 'philips',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'photography',\n",
       " 'photos',\n",
       " 'physio',\n",
       " 'pics',\n",
       " 'pictet',\n",
       " 'pictures',\n",
       " 'pid',\n",
       " 'pin',\n",
       " 'ping',\n",
       " 'pink',\n",
       " 'pioneer',\n",
       " 'pizza',\n",
       " 'pk',\n",
       " 'pl',\n",
       " 'place',\n",
       " 'play',\n",
       " 'playstation',\n",
       " 'plumbing',\n",
       " 'plus',\n",
       " 'pm',\n",
       " 'pn',\n",
       " 'pnc',\n",
       " 'pohl',\n",
       " 'poker',\n",
       " 'politie',\n",
       " 'porn',\n",
       " 'post',\n",
       " 'pr',\n",
       " 'pramerica',\n",
       " 'praxi',\n",
       " 'press',\n",
       " 'prime',\n",
       " 'pro',\n",
       " 'prod',\n",
       " 'productions',\n",
       " 'prof',\n",
       " 'progressive',\n",
       " 'promo',\n",
       " 'properties',\n",
       " 'property',\n",
       " 'protection',\n",
       " 'pru',\n",
       " 'prudential',\n",
       " 'ps',\n",
       " 'pt',\n",
       " 'pub',\n",
       " 'pw',\n",
       " 'pwc',\n",
       " 'py',\n",
       " 'qa',\n",
       " 'qpon',\n",
       " 'quebec',\n",
       " 'quest',\n",
       " 'qvc',\n",
       " 'racing',\n",
       " 'radio',\n",
       " 'raid',\n",
       " 're',\n",
       " 'read',\n",
       " 'realestate',\n",
       " 'realtor',\n",
       " 'realty',\n",
       " 'recipes',\n",
       " 'red',\n",
       " 'redstone',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_known_tlds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_suspicious_tlds():\n",
    "    with open('top_abused_tlds.txt') as file:\n",
    "        tlds = file.read().split('\\n')\n",
    "        tlds = [tld.lower() for tld in tlds]\n",
    "        return tlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.fit', '.tk', '.gq', '.ga', '.ml', '.cf', '.work', '.date', '.wang', '.men']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_suspicious_tlds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_suspicious_words():\n",
    "    with open('suspicious_words.txt') as file:\n",
    "        words = file.read().split('\\n')\n",
    "        words = [tld.lower() for tld in words]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['account',\n",
       " 'webscr',\n",
       " 'login',\n",
       " 'ebayisapi',\n",
       " 'signin',\n",
       " 'banking',\n",
       " 'confirm',\n",
       " 'secure',\n",
       " 'images',\n",
       " 'exe',\n",
       " 'account',\n",
       " 'node.php',\n",
       " 'username',\n",
       " 'password',\n",
       " 'urs',\n",
       " 'user',\n",
       " 'pass',\n",
       " 'pwd']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_suspicious_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tld(url):\n",
    "    try:\n",
    "        index = url.index('/')\n",
    "    except ValueError:\n",
    "        index = len(url) - 1\n",
    "\n",
    "    dot_index = url.rfind('.', 0, index)\n",
    "\n",
    "    try:\n",
    "        index = url.index(':', dot_index, index + 1)\n",
    "    except ValueError:\n",
    "        ()\n",
    "\n",
    "    return url[(dot_index + 1):index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_of_url(url):\n",
    "    return len(url)\n",
    "\n",
    "\n",
    "def is_tld_in_known_list(tld, known_list):\n",
    "    return tld in known_list\n",
    "\n",
    "\n",
    "def is_tld_in_suspicious_list(tld, suspicious_list):\n",
    "    return tld in suspicious_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_url_contain_ip_address(url):\n",
    "    try:\n",
    "        if ip.ip_address(url):\n",
    "            return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def len_of_deep_url(url):\n",
    "    try:\n",
    "        index = url.index('/')\n",
    "        return len(url[index:])\n",
    "    except ValueError:\n",
    "        return len(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_gen_delimiters_in_url(url):\n",
    "    return sum([1 if item in url else 0 for item in gen_delims])\n",
    "\n",
    "\n",
    "def number_of_sub_delimiters_in_url(url):\n",
    "    return sum([1 if item in url else 0 for item in sub_delims])\n",
    "\n",
    "\n",
    "def number_of_reserved_characters_in_url(url):\n",
    "    return number_of_gen_delimiters_in_url(url) + number_of_sub_delimiters_in_url(url)\n",
    "\n",
    "\n",
    "def number_of_unreserved_special_characters_in_url(url):\n",
    "    return sum([1 if item in url else 0 for item in unreserved_characters])\n",
    "\n",
    "\n",
    "def number_of_sub_domains(url):\n",
    "    try:\n",
    "        index = url.index('/')\n",
    "        return len(url[index:].split('.'))\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_url_contain_http_inside(url):\n",
    "    return 'http' in url[1:]\n",
    "\n",
    "\n",
    "def remove_http_from_begining(url):\n",
    "    if url.startswith('http://www.'):\n",
    "        return url[11:]\n",
    "    elif url.startswith('http://'):\n",
    "        return url[7:]\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_suspicious_words_in_url(url, list_of_words):\n",
    "    return sum(item in url for item in list_of_words)\n",
    "\n",
    "\n",
    "def count_percent_character_in_url(url):\n",
    "    return url.count('%')\n",
    "\n",
    "\n",
    "def count_number_of_digits_in_url(url):\n",
    "    return sum(c.isdigit() for c in url)\n",
    "\n",
    "\n",
    "def number_length_ration_in_url(url):\n",
    "    return count_number_of_digits_in_url(url) / len_of_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_url_contain_equal_sign_after_question_mark(url):\n",
    "    try:\n",
    "        index = url.index('?')\n",
    "        return '=' in url[index:]\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def does_url_contain_non_standard_port(url):\n",
    "    tmp = re.search(\":([0-9].?.?.?)\", url)\n",
    "    try:\n",
    "        port = tmp.group(0)[1:]\n",
    "        return (port != '8080') and (port != '80') and (port != '443')\n",
    "    except AttributeError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420464\n",
      "411248\n",
      "(411248, 2)\n",
      "(411466, 5)\n"
     ]
    }
   ],
   "source": [
    "file = 'data.csv'\n",
    "df = pd.read_csv(file, converters={'label': transform_class}, low_memory=False)\n",
    "print(len(df))\n",
    "df.drop_duplicates(subset=None, inplace=True)\n",
    "print(len(df))\n",
    "print(df.shape)\n",
    "df_whois = pd.read_csv('whois_data.csv', low_memory=False)\n",
    "df = pd.merge(df, df_whois, how='inner', on='url')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skup ne sadrzi nijednu NaN vrednost\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if df.isnull().values.any():\n",
    "    print(\"Skup sadrzi NaN vrednosti!\\n\")\n",
    "else:\n",
    "    print(\"Skup ne sadrzi nijednu NaN vrednost\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     rd    ed    ud\n",
      "0  4934   179   184\n",
      "1    -1    -1    -1\n",
      "2  4934   179   184\n",
      "3  5378   100   264\n",
      "4  6003   206   157\n",
      "5  4789   324    40\n",
      "6  3472   180   184\n",
      "7  5914  1318    -1\n",
      "8   223   142    54\n",
      "9  4482   630  1185\n"
     ]
    }
   ],
   "source": [
    "x = df.values[:, 0]\n",
    "y = df.values[:, 1]\n",
    "y = y.astype('int')\n",
    "\n",
    "df_whois = df[['rd', 'ed', 'ud']]\n",
    "print(df_whois.head(10))\n",
    "whois_rd = df_whois.values[:, 0]\n",
    "whois_ed = df_whois.values[:, 1]\n",
    "whois_ud = df_whois.values[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [remove_http_from_begining(item) for item in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_tlds = load_known_tlds()\n",
    "abused_tlds = load_suspicious_tlds()\n",
    "suspicious_words = load_suspicious_words()\n",
    "data_columns = ['url', 'url_len', 'tld_in_known', 'tld_in_abused', 'contain_ip', 'deep_url_len', 'num_of_gen_deli',\n",
    "                    'num_of_sub_deli', 'num_of_reserved_char', 'num_of_unreserved_spec_char', 'num_of_sub_domains',\n",
    "                    'contain_http', 'number_of_suspicious_words', 'number_of_percentage_signs', 'number_of_numbers',\n",
    "                    'number_of_numbers_length_of_url_ratio', 'contain_equal_sign_after_question_mark',\n",
    "                    'contain_non_standard_port', 'whois_rd', 'whois_ed', 'whois_ud', 'class']\n",
    "\n",
    "data_list = [data_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for (i, url) in enumerate(x):\n",
    "    url_string = url\n",
    "    url_string = url\n",
    "    url_len = len_of_url(url)\n",
    "    url_tld = scrape_tld(url)\n",
    "    is_tld_known = is_tld_in_known_list(url_tld, known_tlds)\n",
    "    is_tld_abused = is_tld_in_suspicious_list(url_tld, abused_tlds)\n",
    "    url_contain_ip = does_url_contain_ip_address(url)\n",
    "    url_deep_url_len = len_of_deep_url(url)\n",
    "    url_num_of_gen_delim = number_of_gen_delimiters_in_url(url)\n",
    "    url_num_of_sub_delim = number_of_sub_delimiters_in_url(url)\n",
    "    url_num_of_res_delim = number_of_reserved_characters_in_url(url)\n",
    "    url_num_of_unres_delim = number_of_unreserved_special_characters_in_url(url)\n",
    "    url_num_of_sub_domains = number_of_sub_domains(url)\n",
    "    url_contain_http = does_url_contain_http_inside(url)\n",
    "    number_of_suspicious_words = count_suspicious_words_in_url(url, suspicious_words)\n",
    "    number_of_percentage_signs = count_percent_character_in_url(url)\n",
    "    number_of_digits = count_number_of_digits_in_url(url)\n",
    "    digits_url_length_ratio = number_length_ration_in_url(url)\n",
    "    url_contain_es_after_qm = does_url_contain_equal_sign_after_question_mark(url)\n",
    "    url_contain_non_standard_port = does_url_contain_non_standard_port(url)\n",
    "    url_class = y[i]\n",
    "\n",
    "    days_since_created = whois_rd[i]\n",
    "    days_until_expires = whois_ed[i]\n",
    "    days_since_last_updated = whois_ud[i]\n",
    "\n",
    "    data_list.append([url_string, url_len, is_tld_known, is_tld_abused, url_contain_ip, url_deep_url_len,\n",
    "                      url_num_of_gen_delim, url_num_of_sub_delim, url_num_of_res_delim, url_num_of_unres_delim,\n",
    "                      url_num_of_sub_domains, url_contain_http, number_of_suspicious_words,\n",
    "                      number_of_percentage_signs, number_of_digits, digits_url_length_ratio,\n",
    "                      url_contain_es_after_qm, url_contain_non_standard_port, days_since_created,\n",
    "                      days_until_expires, days_since_last_updated, url_class])\n",
    "\n",
    "    c += 1\n",
    "    if(c%10000 == 0):\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_for_classification_tmp.csv', 'w', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for row in data_list:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
